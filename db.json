{
  "models": [
    {
      "id": 0,
      "name": "GPT-3.5-Turbo",
      "developer": "Open AI",
      "logo": "./images/gpt1.jpeg",
      "snippet_code": "./images/gpt2.jpeg",
      "description": "Generative Pre-trained Transformer 3.5 (GPT-3.5) is a sub class of GPT-3 Models created by OpenAI in 2022. On June 11, 2018, OpenAI researchers and engineers published a paper introducing the first generative pre-trained transformer (GPT)—a type of generative large language model that is pre-trained with an enormous and diverse text corpus in datasets, followed by discriminative fine-tuning to focus on a specific task. GPT models are transformer-based deep-learning neural network architectures. This attention mechanism allows the model to selectively focus on segments of input text it predicts to be most relevant. ",
      "use_case": ["Content Generation","Customer Support","Language Translation","Educational Tools","Creative Writing","Personal Assistants","Code Generation","Content Summarization","Psychological Therapy","Language Learning"],
      "favourite": true,
      "try_out": true,
      "speech_recognition": false,
      "computer_vision": false,
      "reinforcement_learning": false,
      "Transformer_Based": true,
      "Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 1,
      "name": "Gemini-Pro-Vision",
      "developer": "Google",
      "logo": "./images/gemini1.jpeg",
      "snippet_code": "./images/gemini2.jpeg",
      "description": "Gemini Vision Pro is a software platform developed by Gemini Digital Technologies. It's designed to provide advanced analytics and data visualization capabilities for businesses, particularly those operating in industrial and manufacturing sectors. It was built from the ground up to be multimodal, which means it can generalize and seamlessly understand, operate across and combine different types of information including text, code, audio, image and video. With a score of 90.0%, Gemini Ultra is the first model to outperform human experts on MMLU (massive multitask language understanding), which uses a combination of 57 subjects such as math, physics, history, law, medicine and ethics for testing both world knowledge and problem-solving abilities.",
      "use_case": ["Text to Image Multimodal integration","Manufacturing Optimization","Language Translation","Educational Tools","Financial Analytics","Personal Assistants","Code Generation","Content Summarization","Environmental Monitoring","Supply Chain Management"],
      "favourite": true,
      "try_out": true,
      "speech_recognition": false,
      "computer_vision": true,
      "reinforcement_learning": true,
      "Transformer_Based": true,
      "Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 2,
      "name": "PaLM 2",
      "developer": "Google",
      "logo": "./images/palm1.jpeg",
      "snippet_code": "./images/palm2.jpeg",
      "description": "Building on this work, PaLM 2 was intoduced, the next generation language model. PaLM 2 is a state-of-the-art language model with improved multilingual, reasoning and coding capabilities. PaLM 2 is more heavily trained on multilingual text, spanning more than 100 languages. This has significantly improved its ability to understand, generate and translate nuanced text — including idioms, poems and riddles — across a wide variety of languages, a hard problem to solve. PaLM 2 also passes advanced language proficiency exams at the “mastery” level. ",
      "use_case": ["Multilinguality","Personal Assistants","Code Generation","Educational Tools","Reasoning"],
      "favourite": true,
      "try_out": false,
      "speech_recognition": false,
      "computer_vision": false,
      "reinforcement_learning": false,
      "Transformer_Based": true,
      "Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 3,
      "name": "Whisper AI",
      "developer": "Open AI",
      "logo": "./images/whisper1.jpeg",
      "snippet_code": "./images/whisper2.jpeg",
      "description": "Whisper is a large language model developed by OpenAI, which is designed to facilitate more privacy-preserving natural language processing (NLP) tasks. OpenAI introduced Whisper as part of its efforts to explore methods for enabling NLP tasks while minimizing the need for centralized data storage and processing. The key feature of Whisper is its focus on privacy preservation. It utilizes a decentralized approach to NLP tasks, meaning that the model can operate without requiring centralized access to large datasets. This decentralized architecture aims to enhance privacy by reducing the potential risks associated with storing and processing sensitive information in a centralized manner.",
      "use_case": ["Transcription Services","Financial Services","Language Translation","Educational Tools","Financial Analytics","Personal Assistants","Code Generation","Content Summarization","Environmental Monitoring","Customer Support"],
      "favourite": true,
      "try_out": true,
      "speech_recognition": true,
      "computer_vision": false,
      "reinforcement_learning": false,
      "Transformer_Based": false,
      "Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 4,
      "name": "DALL-E-2",
      "developer": "Open AI",
      "logo": "./images/dalle1.jpeg",
      "snippet_code": "./images/dalle2.jpeg",
      "description": "DALL-E is an artificial intelligence model developed by OpenAI that specializes in generating images from textual descriptions. Its name is a combination of DALI (short for Differentiable ALgorithm for generating Images) and E, representing the idea of an evolution from GPT-3, another model by OpenAI. DALL-E is based on a variant of the GPT (Generative Pre-trained Transformer) architecture, which is a type of deep learning model known for its effectiveness in natural language processing tasks.",
      "use_case": ["Image to Text Multimodal integration","Creative Content Generation","Product Design and Prototyping","E-commerce Visuals","Storyboarding and Concept Art","Interior Design and Architecture","Educational Illustrations"],
      "favourite": true,
      "try_out": true,
      "speech_recognition": false,
      "computer_vision": true,
      "reinforcement_learning": false,
      "Transformer_Based": true,
      "Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 5,
      "name": "Llama 2",
      "developer": "Meta",
      "logo": "./images/llama1.jpeg",
      "snippet_code": "./images/llama2.jpeg",
      "description": "Llama 2 is a family of LLMs like GPT-3 and PaLM 2. While there are some technical differences between it and other LLMs, you would really need to be deep into AI for them to mean much. All these LLMs were developed and work in essentially the exact same way; they all use the same transformer architecture and development ideas like pretraining and fine-tuning. When you enter a text prompt or provide Llama 2 with text input in some other way, it attempts to predict the most plausible follow-on text using its neural network—a cascading algorithm with billions of variables (called parameters) that's modeled after the human brain. By assigning different weights to all the different parameters, and throwing in a small bit of randomness, Llama 2 can generate incredibly human-like responses. ",
      "use_case": ["Creative Content Generation"," specialized chatbots","knowledge and information retrieval search engines","Educational Tools","automatic content creators"],
      "favourite": true,
      "try_out": false,
      "speech_recognition": false,
      "computer_vision": false,
      "reinforcement_learning": false,
      "Transformer_Based": true,
      "Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 6 ,
      "name": "Claude 2",
      "developer": "Anthropic",
      "logo": "./images/claude1.jpeg",
      "snippet_code": "./images/claude2.jpeg",
      "description": "Claude is an Artificial Intelligence, trained by Anthropic using Constitutional AI to be safe, accurate, and secure — the best assistant for you to do your best work. If you can dream it, Claude can help you do it. Claude can process large amounts of information, brainstorm ideas, generate text and code, help you understand subjects, coach you through difficult situations, help simplify your busywork so you can focus on what matters most, and so much more.",
      "use_case": ["Personal Assistant","Advanced math and coding skills","Co-worker","Language Tandem Partner","Tone Changer","Summarizer"],
      "favourite": true,
      "try_out": false,
      "speech_recognition": false,
      "computer_vision": false,
      "reinforcement_learning": true,
      "Transformer_Based": false,
      "Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 7,
      "name": "Falcon",
      "developer": "Technology Innovation Institute",
      "logo": "./images/falcon1.jpeg",
      "snippet_code": "./images/falcon2.jpeg",
      "description": "Falcon LLM is a generative large language model (LLM) that helps advance applications and use cases to future-proof our world. Today the Falcon 180B, 40B, 7.5B, 1.3B parameter AI models, as well as our high-quality REFINEDWEB dataset, form a suite of offerings. Falcon 40B was the world’s top-ranked open-source AI model when launched. Falcon has 40 billion parameters and was trained on one trillion tokens. For two months following its launch, Falcon 40B ranked #1 on Hugging Face's leaderboard for open source large language models (LLMs).",
      "use_case": ["Natural language processing (NLP)","Generative text tasks","Chatbots","Machine translation","Research","Code Generation"],
      "favourite": true,
      "try_out": false,
      "speech_recognition": false,
      "computer_vision": true,
      "reinforcement_learning": false,
      "Transformer_Based": true,
      "Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 8,
      "name": "ResNet",
      "developer": "Microsoft",
      "logo": "./images/resnet1.jpeg",
      "snippet_code": "./images/resnet2.jpeg",
      "description": "ResNet, or Residual Network, is a deep convolutional neural network architecture known for its use in image classification. It utilizes skip connections to address the vanishing gradient problem. ResNet is designed to address the problem of vanishing gradients in very deep neural networks, which often hinders training by making it difficult for information to propagate through many layers.",
      "use_case": ["Image Classification","Object Detection","Semantic Segmentation","Instance Segmentation","Medical Image Analysis","Video Surveillance"],
      "favourite": true,
      "try_out": false,
      "speech_recognition": false,
      "computer_vision": true,
      "reinforcement_learning": false,
      "Transformer_Based": false,
      "Convolutional/Convolutional/Recurrent_Neural_Networks": true
    },
    {
      "id": 9,
      "name": "EfficientNet",
      "developer": "Google",
      "logo": "./images/efficientnet1.jpeg",
      "snippet_code": "./images/efficientnet2.jpeg",
      "description": "EfficientNet is a family of convolutional neural network (CNN) architectures proposed by Mingxing Tan and Quoc V. Le from Google Research in their paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,published in 2019. EfficientNet is designed to achieve state-of-the-art performance on image classification tasks while maintaining efficiency in terms of model size and computational resources.",
      "use_case": ["Image Classification","Object Detection","Semantic Segmentation","Instance Segmentation","Transfer Learning and Fine-Tuning"],
      "favourite": false,
      "try_out": false,
      "speech_recognition": false,
      "computer_vision": true,
      "reinforcement_learning": false,
      "Transformer_Based": false,
      "Convolutional/Convolutional/Recurrent_Neural_Networks": true
    },
    {
      "id": 10,
      "name": "DeepSpeech",
      "developer": "Mozilla",
      "logo": "./images/deepspeech1.jpeg",
      "snippet_code": "./images/deepspeech2.jpeg",
      "description": "DeepSpeech AI refers to Mozilla's open-source automatic speech recognition (ASR) engine known as DeepSpeech. It is based on deep learning techniques and is designed to convert spoken language into text. DeepSpeech AI has gained popularity due to its accuracy, flexibility, and open-source nature. It is built on deep learning techniques, particularly recurrent neural networks (RNNs), which are well-suited for sequential data like speech.",
      "use_case": ["Virtual Assistants and Voice-Controlled Devices","Transcription Services","Accessibility Tools","Voice Search and Voice Commands","Customer Service and Call Center Solutions","Language Learning and Education"],
      "favourite": true,
      "try_out": false,
      "speech_recognition": true,
      "computer_vision": false,
      "reinforcement_learning": false,
      "Transformer_Based": false,
      "Convolutional/Convolutional/Recurrent_Neural_Networks": true 
    },
    {
      "id": 11,
      "name": "Speech-to-Text",
      "developer": "Google",
      "logo": "./images/speechtotext1.jpeg",
      "snippet_code": "./images/speechtotext2.jpeg",
      "description": "Google Speech-to-Text AI, also known as Google Cloud Speech-to-Text, is a cloud-based service provided by Google that enables developers to convert spoken language into text. It uses advanced machine learning models to accurately transcribe audio in real-time, making it suitable for a wide range of applications and use cases. Google Speech-to-Text AI leverages deep learning techniques, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformer models, to process and transcribe audio inputs. These models are trained on vast amounts of data to accurately recognize and understand spoken language.",
      "use_case": ["Virtual Assistants and Voice-Controlled Devices","Medical and Healthcare Service","Accessibility Tools","Voice Search and Voice Commands","Customer Service and Call Center Solutions","Language Learning and Education"],
      "favourite": false,
      "try_out": false,
      "speech_recognition": true,
      "computer_vision": false,
      "reinforcement_learning": false,
      "Transformer_Based": true,
      "Convolutional/Convolutional/Recurrent_Neural_Networks": true 
    },
    {
      "id": 12,
      "name": "Deep Q-Networks",
      "developer": "Q-learning",
      "logo": "./images/dqn1.jpeg",
      "snippet_code": "./images/dqn2.jpeg",
      "description": "Deep Q-Networks (DQN) is a deep reinforcement learning algorithm that combines Q-learning with deep neural networks to handle high-dimensional state spaces. It was introduced by researchers at DeepMind in their seminal paper Playing Atari with Deep Reinforcement Learning in 2013.",
      "use_case": ["Game Playing","Robotics","Autonomous Vehicles","Recommendation Systems","Resource Management"],
      "favourite": false,
      "try_out": false,
      "speech_recognition": false,
      "computer_vision": false,
      "reinforcement_learning": true,
      "Transformer_Based": false,
      "Convolutional/Convolutional/Recurrent_Neural_Networks": false
    },
    {
      "id": 13,
      "name": "AlphaGo",
      "developer": "DeepMind Technologies(Google)",
      "logo": "./images/alphago1.jpeg",
      "snippet_code": "./images/alphago.jpeg",
      "description": "AlphaGo is an artificial intelligence (AI) program developed by DeepMind Technologies, a subsidiary of Alphabet Inc. (Google's parent company), that became famous for its groundbreaking achievements in playing the board game Go. It represents a significant milestone in the field of AI and has demonstrated the ability of AI to master complex games. AlphaGo employs a Monte Carlo Tree Search algorithm, a common technique used in game-playing AI systems. MCTS is a heuristic search algorithm that iteratively builds a search tree of possible moves and their outcomes. It selects actions based on a balance of exploration (trying new moves) and exploitation (selecting moves with high estimated value).",
      "use_case": ["Algorithmic Trading","Supply Chain Optimization","Healthcare Decision Support","Natural Language Processing (NLP)","Autonomous Vehicles","Personalized Recommendations"],
      "favourite": false,
      "try_out": false,
      "speech_recognition": false,
      "computer_vision": false,
      "reinforcement_learning": true,
      "Transformer_Based": true,
      "Convolutional/Convolutional/Recurrent_Neural_Networks": false
    }
  ]
}
